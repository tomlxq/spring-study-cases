# 性能测试与优化

功能验证 懂业务

拓展验证 懂技术

质量保证 懂沟通

## 性能测试是什么

为了验证在一定环境下系统满足性能需求的测试，主要是验证性能指标（响应时间，吞吐量，资源利用率，并发用户数）

用最低的资源做最高的处理能力和低的响应时间

多节点的容器化（docker,spring boot)

* 响应时间

  完成一个业务所需要的时间综合，越短越好。

* 吞吐量

  单位时间里处理的业务越多越好

* 资源利用率

  完成业务需要开销，CPU，内存，IO

## 行业内做性能测试

IOE指的是去掉IBM的小型机、Oracle(甲骨文)数据库、EMC存储设备

>  首先，很多人对于去IOE不是很了解，认为只是单纯的不使用IBM、Oracle、EMC的产品。去IOE，其中的I指的是IBM的小型机，O指的是Oracle的数据库，E指的是EMC的高端存储。再谈一谈这三个产品各自的优势，IBM的产品，在我国的金融行业中占据着绝对的优势，Oracle的数据库，在电信、证券行业占着相当大的份额，EMC的存储，在银行、电信、证券等垄断行业，都占据着较大的份额，要知道，EMC是全球最大的存储公司。

* tpc

  相当于高考 transaction processing performance council

  TPC-A、TPC-B、TPC-D、TPC-R

  给一个标准的业务，比完成业务的能力（消耗多少资源换多少处理能力）

* spec

  相当于智商测试，由standard performance evaluation corp 制定

  物理业务能力，比较固定业务换算能力

测试人员 关注tpc，强调业务下的处理能力

运维人员 spec强调资源处理能力

## 如何做性能测试

模拟客户端对服务器的多线程调用

testNG，效率低，不支持分布式

apache ab 或 Jemeter 支持分布式

工具 协议模拟和接口调用

### 性能测试原理

模拟客户端对服务器进行多连接伪造报文件欺骗服务器认证机制

1. 了解服务器的认证机制
2. 了解客户端，服务器之间交流报文结构
3. 合理的技术构造报文结构

协议基础

* 报文体系
  * 抓包工具 F12、Fiddler、charls
  * 发包工具 Postman、Curl、Httpclient
* 报文结构
  * request： header Body
  * Response ： header Body

性能测试技术

* 负载 制造多用户
* 参数化 用户之间的数据变化
* 关联 前后业务的衔接数据
* 事务 完成任务的响应时间
* 监控 资源及相关变化

### 性能工具需要解决的问题

* 并发负载用户

  为什么需要并发这么多用户

* 参数化

  避免缓存带来的性能问题

* 关联

  业务前后依赖（token 主键关键字）

* 事务

  通过函数来明确具体业务的时间范围
  
* 监控

  * 监控负载

    响应时间，吞吐量的监控

  * 监控资源 

    * JVM监控工具

      jrock jmap jprofile

    * zabbix

    * elk

    * 普洛尔米修斯

    * TOP

    系统资源的监控，是运维干的apache jemeter

## 性能测试的实施

性能需求是啥

测试方式是啥

结果怎么收集

报告怎么编写

### 性能测试模型

* 单用户单业务串行测试，评估单独业务的响应时间

* 多用户的并发测试 了解响应时间的转折点，队列、资源不足、处理能力的峰值

| 理发师模式 |           |                         |      |          |
| ---------- | --------- | ----------------------- | ---- | -------- |
|            | 1         | 有一个理发店有3个师傅   |      |          |
|            | 2         | 每个师傅理发需要1个小时 |      |          |
|            | 3         | 用户最多等2个小时       |      |          |
|            |           |                         |      |          |
| Vuser      | wait time | response time           | tps  | resource |
| 1          | 0         | 1                       | 1    | 0.3      |
| 2          | 0         | 1                       | 1    | 0.6      |
| 3          | 0         | 1                       | 1    | 1        |
| 4          | 1         | 2                       | 2    | 1        |
| 5          | 1         | 2                       | 2    | 1        |
| 6          | 1         | 2                       | 2    | 1        |
| 7          | 2         | 3                       | 3    | 1        |
| 8          | 2         | 3                       | 3    | 1        |
| 9          | 2         | 3                       | 3    | 1        |

| 任何工具最后都会得到 |
| -------------------- |
| 响应时间             |
| tips                 |
| 资源利用率           |
| 负载用户数           |

![1564066082385](img\lifashi1.png)

随着并发数的增加，响应时间越来越慢

![1564066150236](img\lifashi2.png)

随着并发数的增加，资源耗尽，处理能力也急剧下降

* 模型结论

  响应时间随着负载的上升先稳定后上升，并且越来越快

  TPS随着负载的上升先到峰值，后稳定，然后下降

![1564067512268](img\lifashi3.png)

当到达A点说明负载导致了队列的产生

B点处理能力已经不能完全占用资源，开始下降了

C点响应时间超时（258，扯蛋）

在Ａ点说明负载小

B点说明系统最佳负载

C点说明系统不能用

所以正常系统应该在A-->B之间，最好不要越过B

特殊情况可以在A和C之间，但是不能超过C

ABC三点右移说明调优成功。

> spotlight

### 配置测试和基准测试

配置测试 通过不同的配置获得数据

基准测试 通过不同配置比较结果

### 性能优化与分析

对已知事务进行了解

使用已知知识对事务进行揣摩

给出自己的理解

### 性能优化

用自己的方式实现，基于实现为基础

用规范的方式实现，基于遵守规范为基础

用超越规范的方式实现，基于定制化规范为基础

> 从低端配置到批量生产再到高端定置

### 常见规范

* 点播为广播

  减少为每个业务的计算量，提高cache命中率，改Get为Push

* 同步为异步

  减少立即处理所带来的阻塞，通过队列形式来预防系统崩溃

* 遵守规范

  使用符合框架规范的处理机制

* 实时计算为预计算

  减少动态请求，可预估数据预先计算，削减峰值